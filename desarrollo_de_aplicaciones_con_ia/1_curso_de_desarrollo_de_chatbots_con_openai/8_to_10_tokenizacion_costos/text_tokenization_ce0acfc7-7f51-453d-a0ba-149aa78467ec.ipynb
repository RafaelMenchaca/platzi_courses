{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenización de texto para calcular costos de uso de OpenAI\n",
    "\n",
    "Fuente: [How_to_count_tokens_with_tiktoken - OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instalación de titktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2025.11.3-cp311-cp311-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ------------------ ------------------- 20.5/41.5 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------- 41.5/41.5 kB 496.6 kB/s eta 0:00:00\n",
      "Collecting requests>=2.26.0 (from tiktoken)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl.metadata (38 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\angel\\documents\\platzi_courses\\platzi_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (3.11)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests>=2.26.0->tiktoken)\n",
      "  Downloading urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\angel\\documents\\platzi_courses\\platzi_venv\\lib\\site-packages (from requests>=2.26.0->tiktoken) (2026.1.4)\n",
      "Downloading tiktoken-0.12.0-cp311-cp311-win_amd64.whl (879 kB)\n",
      "   ---------------------------------------- 0.0/879.4 kB ? eta -:--:--\n",
      "   ----- ---------------------------------- 112.6/879.4 kB 3.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 501.8/879.4 kB 7.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 879.4/879.4 kB 9.2 MB/s eta 0:00:00\n",
      "Downloading regex-2025.11.3-cp311-cp311-win_amd64.whl (277 kB)\n",
      "   ---------------------------------------- 0.0/277.7 kB ? eta -:--:--\n",
      "   --------------------------------------- 277.7/277.7 kB 16.7 MB/s eta 0:00:00\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.4-cp311-cp311-win_amd64.whl (106 kB)\n",
      "   ---------------------------------------- 0.0/107.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 107.0/107.0 kB ? eta 0:00:00\n",
      "Downloading urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "   ---------------------------------------- 0.0/131.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 131.6/131.6 kB ? eta 0:00:00\n",
      "Installing collected packages: urllib3, regex, charset_normalizer, requests, tiktoken\n",
      "Successfully installed charset_normalizer-3.4.4 regex-2025.11.3 requests-2.32.5 tiktoken-0.12.0 urllib3-2.6.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección y carga de encoding \n",
    "\n",
    "`cl100k_base` para modelos `gpt-4, gpt-3.5-turbo, text-embedding-ada-002`.\n",
    "\n",
    "Consulta el [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb) para otro tipo de modelos o cambios en este encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenización de string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[301, 281, 618, 6491, 2586, 2092, 6491]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoding.encode(\"el perrito come solito\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(encoding.encode(\"El perrito come solito.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizar una serie de mensajes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\"):\n",
    "    \"\"\"Return the number of tokens used by a list of messages.\"\"\"\n",
    "    try:\n",
    "        encoding = tiktoken.encoding_for_model(model)\n",
    "    except KeyError:\n",
    "        print(\"Warning: model not found. Using cl100k_base encoding.\")\n",
    "        encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "    if model in {\n",
    "        \"gpt-3.5-turbo-0613\",\n",
    "        \"gpt-3.5-turbo-16k-0613\",\n",
    "        \"gpt-4-0314\",\n",
    "        \"gpt-4-32k-0314\",\n",
    "        \"gpt-4-0613\",\n",
    "        \"gpt-4-32k-0613\",\n",
    "        }:\n",
    "        tokens_per_message = 3\n",
    "        tokens_per_name = 1\n",
    "    elif model == \"gpt-3.5-turbo-0301\":\n",
    "        tokens_per_message = 4  # every message follows <|start|>{role/name}\\n{content}<|end|>\\n\n",
    "        tokens_per_name = -1  # if there's a name, the role is omitted\n",
    "    elif \"gpt-3.5-turbo\" in model:\n",
    "        print(\"Warning: gpt-3.5-turbo may update over time. Returning num tokens assuming gpt-3.5-turbo-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-3.5-turbo-0613\")\n",
    "    elif \"gpt-4\" in model:\n",
    "        print(\"Warning: gpt-4 may update over time. Returning num tokens assuming gpt-4-0613.\")\n",
    "        return num_tokens_from_messages(messages, model=\"gpt-4-0613\")\n",
    "    else:\n",
    "        raise NotImplementedError(\n",
    "            f\"\"\"num_tokens_from_messages() is not implemented for model {model}. See https://github.com/openai/openai-python/blob/main/chatml.md for information on how messages are converted to tokens.\"\"\"\n",
    "        )\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3  # every reply is primed with <|start|>assistant<|message|>\n",
    "    return num_tokens  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_messages = [\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": \"Eres un asistente de atención a clientes y estudiantes de la plataforma de educación online en tecnología, inglés y liderazgo llamada Platzi\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"¿Cómo puedo mejorar mis habilidades de creación de contenido con inteligencia artificial?\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"Para mejorar tus habilidades de creación de contenido con inteligencia artificial te sugiero que tomes el Taller de Creación de Contenido con Inteligencia Artificial en https://platzi.com/cursos/contenido-ia/. En este curso aprenderás a utilizar herramientas para generar contenido de manera automatizada y eficiente. ¡No te lo pierdas!\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "139"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens_from_messages(example_messages, model=\"gpt-3.5-turbo-0613\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "platzi_venv (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
